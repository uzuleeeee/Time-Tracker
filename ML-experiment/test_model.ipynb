{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4607d0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac-aroni/miniforge3/envs/time-tracker-ml/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "class CategoryScorer:\n",
    "    def __init__(self):\n",
    "        self.model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "        \n",
    "        self.max_description_length = 20\n",
    "        \n",
    "        # Define categories and initial descriptions\n",
    "        self.category_data = {\n",
    "            \"Sleep\": [\n",
    "                \"Going to sleep\", \n",
    "                \"Taking a nap\", \n",
    "                \"Heading to bed\", \n",
    "                \"Resting my eyes\", \n",
    "                \"Unconscious\", \n",
    "                \"Catching some Zs\"\n",
    "            ],\n",
    "            \"Break\": [\n",
    "                \"Taking a short break\", \n",
    "                \"Pausing work for a bit\", \n",
    "                \"Relaxing for a moment\", \n",
    "                \"Procrastinating\", \n",
    "                \"Chilling out\", \n",
    "                \"Stopping to rest\"\n",
    "            ],\n",
    "            \"Coding\": [\n",
    "                \"Writing code\", \n",
    "                \"Debugging an application\", \n",
    "                \"Programming software\", \n",
    "                \"Developing in Python or Swift\", \n",
    "                \"Building a feature\", \n",
    "                \"Fixing a bug\"\n",
    "            ],\n",
    "            \"Errands\": [\n",
    "                \"Doing household chores\", \n",
    "                \"Doing laundry\", \n",
    "                \"Washing the dishes\", \n",
    "                \"Cleaning the house\", \n",
    "                \"Grocery shopping\", \n",
    "                \"Tidying up the room\"\n",
    "            ],\n",
    "            \"Fitness\": [\n",
    "                \"Working out\", \n",
    "                \"Going for a run\", \n",
    "                \"Lifting weights at the gym\", \n",
    "                \"Doing cardio\", \n",
    "                \"Playing sports\", \n",
    "                \"Exercising\"\n",
    "            ],\n",
    "            \"Meditation\": [\n",
    "                \"Meditating\", \n",
    "                \"Practicing mindfulness\", \n",
    "                \"Doing deep breathing exercises\", \n",
    "                \"Yoga session\", \n",
    "                \"Sitting quietly\"\n",
    "            ],\n",
    "            \"Study\": [\n",
    "                \"Studying for an exam\", \n",
    "                \"Doing homework\", \n",
    "                \"Reading a textbook\", \n",
    "                \"Writing an essay\", \n",
    "                \"Learning a new subject\", \n",
    "                \"Classwork\"\n",
    "            ],\n",
    "            \"Work\": [\n",
    "                \"Working at my job\", \n",
    "                \"Sitting at my desk working\", \n",
    "                \"In a meeting\", \n",
    "                \"Answering emails\", \n",
    "                \"Professional business tasks\", \n",
    "                \"Career work\"\n",
    "            ],\n",
    "            \"Leisure\": [\n",
    "                \"Watching TV\", \n",
    "                \"Playing video games\", \n",
    "                \"Watching a movie\", \n",
    "                \"Scroll social media\", \n",
    "                \"Having fun\", \n",
    "                \"Hobby time\", \n",
    "                \"Relaxing on the couch\"\n",
    "            ],\n",
    "            \"Eat\": [\n",
    "                \"Eating a meal\", \n",
    "                \"Having breakfast\", \n",
    "                \"Grabbing lunch\", \n",
    "                \"Eating dinner\", \n",
    "                \"Having a snack\", \n",
    "                \"Drinking water\"\n",
    "            ],\n",
    "            \"Commute\": [\n",
    "                \"Commuting to work\", \n",
    "                \"Driving to the office\", \n",
    "                \"Walking to school\", \n",
    "                \"Heading to a destination\", \n",
    "                \"Taking the bus or train\", \n",
    "                \"Riding a bike\", \n",
    "                \"Traveling\",\n",
    "                \"Going to work\" \n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Split category descriptions\n",
    "        for category, descriptions in self.category_data.items():\n",
    "            if len(descriptions) == 1 and \",\" in descriptions[0]:\n",
    "                clean_list = [d.strip() for d in descriptions[0].split(',') if d.strip()]\n",
    "                self.category_data[category] = clean_list\n",
    "        \n",
    "        # Pre-calculate vectors for existing categories\n",
    "        self.category_vectors = {}\n",
    "        self.calculate_all_category_vectors()\n",
    "\n",
    "    def predict(self, text):\n",
    "        similarities = []\n",
    "        \n",
    "        # Get vector embedding of input text\n",
    "        text_embedding = self.model.encode(text, normalize_embeddings=True)\n",
    "        \n",
    "        # Get words in input text\n",
    "        text_words = set(text.lower().split())\n",
    "        \n",
    "        # Compare input vector with all category vectors\n",
    "        for category, category_embedding in self.category_vectors.items():    \n",
    "            vector_score = np.dot(text_embedding, category_embedding)\n",
    "            \n",
    "            description_words = set(self.get_full_description(category))\n",
    "            intersection = len(text_words.intersection(description_words))\n",
    "            keyword_boost = 0.1 * intersection\n",
    "            \n",
    "            final_score = vector_score + keyword_boost\n",
    "            \n",
    "            similarities.append((category, final_score))\n",
    "            \n",
    "        # Sort similarities by score\n",
    "        similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "        return similarities\n",
    "    \n",
    "    def get_full_description(self, category):\n",
    "        return [category] + self.category_data[category]\n",
    "    \n",
    "    def get_category_vector(self, category):\n",
    "        full_description = self.get_full_description(category)\n",
    "        embeddings = self.model.encode(full_description, normalize_embeddings=True)\n",
    "        embeddings[0, :] *= 3\n",
    "        \n",
    "        centroid = np.mean(embeddings, axis=0)\n",
    "        normalized_centroid = centroid / np.linalg.norm(centroid)\n",
    "        \n",
    "        return normalized_centroid\n",
    "    \n",
    "    def calculate_all_category_vectors(self):\n",
    "        for category in self.category_data:\n",
    "            self.category_vectors[category] = self.get_category_vector(category)\n",
    "            \n",
    "    def update_category(self, category, text):\n",
    "        if category not in self.category_data:\n",
    "            self.category_data[category] = []\n",
    "        \n",
    "        self.category_data[category].append(text)\n",
    "        \n",
    "        if len(self.category_data[category]) > self.max_description_length:\n",
    "            self.category_data[category] = self.category_data[category][1:]\n",
    "        \n",
    "        self.category_vectors[category] = self.get_category_vector(category)\n",
    "        \n",
    "# --- THE INTERACTIVE LOOP ---\n",
    "\n",
    "scorer = CategoryScorer()\n",
    "\n",
    "while True:\n",
    "    print(\"-\" * 60)\n",
    "    user_input = input(\"Enter activity (or 'q' to quit): \")\n",
    "    \n",
    "    if user_input.lower() in ['q', 'quit', 'exit']:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "        \n",
    "    if not user_input.strip():\n",
    "        continue\n",
    "\n",
    "    # 1. Get Predictions\n",
    "    predictions = scorer.predict(user_input)\n",
    "    top_category = predictions[0][0]\n",
    "    top_score = predictions[0][1]\n",
    "\n",
    "    # 2. Display Dashboard\n",
    "    print(f\"\\nüìù Input: '{user_input}'\")\n",
    "    print(f\"ü§ñ Top Prediction: {top_category} ({top_score:.3f})\\n\")\n",
    "    \n",
    "    print(\"Scores:\")\n",
    "    for i, (cat, score) in enumerate(predictions[:10]): # Show Top 10\n",
    "        bar = \"‚ñà\" * int(score * 20)\n",
    "        print(f\"  [{i}] {cat:<12} {score:.3f}  {bar}\")\n",
    "    \n",
    "    # 3. User Feedback Loop\n",
    "    print(\"\\nActions:\")\n",
    "    print(\"  [Enter] Confirm Top Match\")\n",
    "    print(\"  [0-9]   Select specific category above\")\n",
    "    print(\"  [n]     Create NEW Category\")\n",
    "    \n",
    "    choice = input(\"Select correct category: \").strip().lower()\n",
    "    \n",
    "    selected_category = None\n",
    "    \n",
    "    # CASE A: Confirm Top Match\n",
    "    if choice == \"\":\n",
    "        selected_category = top_category\n",
    "        # Only learn if confidence was low, otherwise skip to save space (Optional rule)\n",
    "        if top_score < 0.8: \n",
    "            scorer.update_category(selected_category, user_input)\n",
    "        else:\n",
    "            print(\"‚úÖ High confidence match. No update needed.\")\n",
    "\n",
    "    # CASE B: Select from List\n",
    "    elif choice.isdigit() and 0 <= int(choice) < 10:\n",
    "        idx = int(choice)\n",
    "        selected_category = predictions[idx][0]\n",
    "        # This is a correction, so we ALWAYS update\n",
    "        scorer.update_category(selected_category, user_input)\n",
    "\n",
    "    # CASE C: Create New Category\n",
    "    elif choice == 'n':\n",
    "        new_cat_name = input(\"Enter name for NEW category: \").strip().title()\n",
    "        if new_cat_name:\n",
    "            selected_category = new_cat_name\n",
    "            # Initialize with user input\n",
    "            scorer.update_category(selected_category, user_input)\n",
    "\n",
    "    # CASE D: Invalid\n",
    "    else:\n",
    "        print(\"‚ùå Invalid selection. Learning skipped.\")\n",
    "\n",
    "    # Pause for effect so user can read result\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c78314f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "class CategoryScorer:\n",
    "    def __init__(self):\n",
    "        self.model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "        \n",
    "        self.max_description_length = 20\n",
    "        \n",
    "        # Define categories and initial descriptions\n",
    "        self.category_data = {\n",
    "            \"Sleep\": [\"Sleep, take a nap, go to bed, rest eyes, unconscious.\"],\n",
    "            \"Break\": [\"Take a break, pause work, relax for a moment, procrastination, chill.\"],\n",
    "            \"Coding\": [\"Write code, programming, software development, debugging, python, swift.\"],\n",
    "            \"Errands\": [\"Do chores, laundry, wash dishes, clean house, buy groceries, housework.\"],\n",
    "            \"Fitness\": [\"Workout, go to the gym, run, lift weights, exercise, cardio, sports.\"],\n",
    "            \"Meditation\": [\"Meditate, mindfulness, deep breathing, yoga, sit quietly.\"],\n",
    "            \"Study\": [\"Study for school, do homework, read textbook, learn new things, class work.\"],\n",
    "            \"Work\": [\"Do my job, work at office, professional tasks, business, career, meetings.\"],\n",
    "            \"Leisure\": [\"Watch TV, watch a movie, play games, entertainment, hobby, fun, relax.\"],\n",
    "            \"Eat\": [\"Eat a meal, have breakfast, lunch, dinner, snack, drink water.\"],\n",
    "            \"Commute\": [\"Commute, travel, drive car, walk to place, take bus, train, ride bike.\"],\n",
    "        }\n",
    "        \n",
    "        # Split category descriptions\n",
    "        for category, descriptions in self.category_data.items():\n",
    "            if len(descriptions) == 1 and \",\" in descriptions[0]:\n",
    "                clean_list = [d.strip() for d in descriptions[0].split(',') if d.strip()]\n",
    "                self.category_data[category] = clean_list\n",
    "        \n",
    "        # Pre-calculate vectors for existing categories\n",
    "        self.category_vectors = {}\n",
    "        self.calculate_all_category_vectors()\n",
    "\n",
    "    def predict(self, text):\n",
    "        similarities = []\n",
    "        \n",
    "        # Get vector embedding of input text\n",
    "        text_embedding = self.model.encode(text, normalize_embeddings=True)\n",
    "        \n",
    "        # Compare input vector with all category vectors\n",
    "        for category, category_embedding in self.category_vectors.items():\n",
    "            similarities.append((category, np.dot(text_embedding, category_embedding)))\n",
    "            \n",
    "        # Sort similarities by score\n",
    "        similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "        return similarities\n",
    "    \n",
    "    def get_category_vector(self, category):\n",
    "        full_description = [category] + self.category_data[category]\n",
    "        embeddings = self.model.encode(full_description, normalize_embeddings=True)\n",
    "        centroid = np.mean(embeddings, axis=0)\n",
    "        normalized_centroid = centroid / np.linalg.norm(centroid)\n",
    "        \n",
    "        return normalized_centroid\n",
    "    \n",
    "    def calculate_all_category_vectors(self):\n",
    "        for category in self.category_data:\n",
    "            self.category_vectors[category] = self.get_category_vector(category)\n",
    "            \n",
    "    def update_category(self, category, text):\n",
    "        if category not in self.category_data:\n",
    "            self.category_data[category] = []\n",
    "        \n",
    "        self.category_data[category].append(text)\n",
    "        \n",
    "        if len(self.category_data[category]) > self.max_description_length:\n",
    "            self.category_data[category] = self.category_data[category][1:]\n",
    "        \n",
    "        self.category_vectors[category] = self.get_category_vector(category)\n",
    "        \n",
    "# --- THE INTERACTIVE LOOP ---\n",
    "\n",
    "scorer = CategoryScorer()\n",
    "\n",
    "while True:\n",
    "    print(\"-\" * 60)\n",
    "    user_input = input(\"Enter activity (or 'q' to quit): \")\n",
    "    \n",
    "    if user_input.lower() in ['q', 'quit', 'exit']:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "        \n",
    "    if not user_input.strip():\n",
    "        continue\n",
    "\n",
    "    # 1. Get Predictions\n",
    "    predictions = scorer.predict(user_input)\n",
    "    top_category = predictions[0][0]\n",
    "    top_score = predictions[0][1]\n",
    "\n",
    "    # 2. Display Dashboard\n",
    "    print(f\"\\nüìù Input: '{user_input}'\")\n",
    "    print(f\"ü§ñ Top Prediction: {top_category} ({top_score:.3f})\\n\")\n",
    "    \n",
    "    print(\"Scores:\")\n",
    "    for i, (cat, score) in enumerate(predictions[:10]): # Show Top 10\n",
    "        bar = \"‚ñà\" * int(score * 20)\n",
    "        print(f\"  [{i}] {cat:<12} {score:.3f}  {bar}\")\n",
    "    \n",
    "    # 3. User Feedback Loop\n",
    "    print(\"\\nActions:\")\n",
    "    print(\"  [Enter] Confirm Top Match\")\n",
    "    print(\"  [0-9]   Select specific category above\")\n",
    "    print(\"  [n]     Create NEW Category\")\n",
    "    \n",
    "    choice = input(\"Select correct category: \").strip().lower()\n",
    "    \n",
    "    selected_category = None\n",
    "    \n",
    "    # CASE A: Confirm Top Match\n",
    "    if choice == \"\":\n",
    "        selected_category = top_category\n",
    "        # Only learn if confidence was low, otherwise skip to save space (Optional rule)\n",
    "        if top_score < 0.8: \n",
    "            scorer.update_category(selected_category, user_input)\n",
    "        else:\n",
    "            print(\"‚úÖ High confidence match. No update needed.\")\n",
    "\n",
    "    # CASE B: Select from List\n",
    "    elif choice.isdigit() and 0 <= int(choice) < 10:\n",
    "        idx = int(choice)\n",
    "        selected_category = predictions[idx][0]\n",
    "        # This is a correction, so we ALWAYS update\n",
    "        scorer.update_category(selected_category, user_input)\n",
    "\n",
    "    # CASE C: Create New Category\n",
    "    elif choice == 'n':\n",
    "        new_cat_name = input(\"Enter name for NEW category: \").strip().title()\n",
    "        if new_cat_name:\n",
    "            selected_category = new_cat_name\n",
    "            # Initialize with user input\n",
    "            scorer.update_category(selected_category, user_input)\n",
    "\n",
    "    # CASE D: Invalid\n",
    "    else:\n",
    "        print(\"‚ùå Invalid selection. Learning skipped.\")\n",
    "\n",
    "    # Pause for effect so user can read result\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aba598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Sleep\": [\n",
    "        \"Going to sleep\", \n",
    "        \"Taking a nap\", \n",
    "        \"Heading to bed\", \n",
    "        \"Resting my eyes\", \n",
    "        \"Unconscious\", \n",
    "        \"Catching some Zs\"\n",
    "    ],\n",
    "    \"Break\": [\n",
    "        \"Taking a short break\", \n",
    "        \"Pausing work for a bit\", \n",
    "        \"Relaxing for a moment\", \n",
    "        \"Procrastinating\", \n",
    "        \"Chilling out\", \n",
    "        \"Stopping to rest\"\n",
    "    ],\n",
    "    \"Coding\": [\n",
    "        \"Writing code\", \n",
    "        \"Debugging an application\", \n",
    "        \"Programming software\", \n",
    "        \"Developing in Python or Swift\", \n",
    "        \"Building a feature\", \n",
    "        \"Fixing a bug\"\n",
    "    ],\n",
    "    \"Errands\": [\n",
    "        \"Doing household chores\", \n",
    "        \"Doing laundry\", \n",
    "        \"Washing the dishes\", \n",
    "        \"Cleaning the house\", \n",
    "        \"Grocery shopping\", \n",
    "        \"Tidying up the room\"\n",
    "    ],\n",
    "    \"Fitness\": [\n",
    "        \"Working out\", \n",
    "        \"Going for a run\", \n",
    "        \"Lifting weights at the gym\", \n",
    "        \"Doing cardio\", \n",
    "        \"Playing sports\", \n",
    "        \"Exercising\"\n",
    "    ],\n",
    "    \"Meditation\": [\n",
    "        \"Meditating\", \n",
    "        \"Practicing mindfulness\", \n",
    "        \"Doing deep breathing exercises\", \n",
    "        \"Yoga session\", \n",
    "        \"Sitting quietly\"\n",
    "    ],\n",
    "    \"Study\": [\n",
    "        \"Studying for an exam\", \n",
    "        \"Doing homework\", \n",
    "        \"Reading a textbook\", \n",
    "        \"Writing an essay\", \n",
    "        \"Learning a new subject\", \n",
    "        \"Classwork\"\n",
    "    ],\n",
    "    \"Work\": [\n",
    "        \"Working at my job\", \n",
    "        \"Sitting at my desk working\", \n",
    "        \"In a meeting\", \n",
    "        \"Answering emails\", \n",
    "        \"Professional business tasks\", \n",
    "        \"Career work\"\n",
    "    ],\n",
    "    \"Leisure\": [\n",
    "        \"Watching TV\", \n",
    "        \"Playing video games\", \n",
    "        \"Watching a movie\", \n",
    "        \"Scroll social media\", \n",
    "        \"Having fun\", \n",
    "        \"Hobby time\", \n",
    "        \"Relaxing on the couch\"\n",
    "    ],\n",
    "    \"Eat\": [\n",
    "        \"Eating a meal\", \n",
    "        \"Having breakfast\", \n",
    "        \"Grabbing lunch\", \n",
    "        \"Eating dinner\", \n",
    "        \"Having a snack\", \n",
    "        \"Drinking water\"\n",
    "    ],\n",
    "    \"Commute\": [\n",
    "        \"Commuting to work\", \n",
    "        \"Driving to the office\", \n",
    "        \"Walking to school\", \n",
    "        \"Heading to a destination\", \n",
    "        \"Taking the bus or train\", \n",
    "        \"Riding a bike\", \n",
    "        \"Traveling\",\n",
    "        \"Going to work\" \n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69086eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "0.6095359921455383 <class 'float'>\n",
      "\n",
      "üìù Input: 'watch instagram'\n",
      "ü§ñ Top Prediction: Leisure (0.610)\n",
      "\n",
      "Scores:\n",
      "  [0] Leisure      0.610  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [1] Eat          0.482  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [2] Break        0.470  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [3] Meditation   0.436  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [4] Commute      0.417  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [5] Fitness      0.414  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [6] Study        0.413  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [7] Sleep        0.382  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [8] Coding       0.369  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [9] Errands      0.368  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Actions:\n",
      "  [Enter] Confirm Top Match\n",
      "  [0-9]   Select specific category above\n",
      "  [n]     Create NEW Category\n",
      "------------------------------------------------------------\n",
      "0.5513965487480164 <class 'float'>\n",
      "\n",
      "üìù Input: 'watching beaver'\n",
      "ü§ñ Top Prediction: Leisure (0.551)\n",
      "\n",
      "Scores:\n",
      "  [0] Leisure      0.551  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [1] Sleep        0.496  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [2] Study        0.495  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [3] Eat          0.481  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [4] Break        0.459  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [5] Errands      0.437  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [6] Work         0.428  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [7] Commute      0.418  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [8] Fitness      0.417  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [9] Coding       0.384  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Actions:\n",
      "  [Enter] Confirm Top Match\n",
      "  [0-9]   Select specific category above\n",
      "  [n]     Create NEW Category\n",
      "‚ùå Invalid selection. Learning skipped.\n",
      "------------------------------------------------------------\n",
      "0.30576634407043457 <class 'float'>\n",
      "\n",
      "üìù Input: 'feeding beaver'\n",
      "ü§ñ Top Prediction: Eat (0.306)\n",
      "\n",
      "Scores:\n",
      "  [0] Eat          0.306  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [1] Study        0.245  ‚ñà‚ñà‚ñà‚ñà\n",
      "  [2] Sleep        0.229  ‚ñà‚ñà‚ñà‚ñà\n",
      "  [3] Leisure      0.213  ‚ñà‚ñà‚ñà‚ñà\n",
      "  [4] Fitness      0.209  ‚ñà‚ñà‚ñà‚ñà\n",
      "  [5] Work         0.203  ‚ñà‚ñà‚ñà‚ñà\n",
      "  [6] Coding       0.197  ‚ñà‚ñà‚ñà\n",
      "  [7] Errands      0.195  ‚ñà‚ñà‚ñà\n",
      "  [8] Meditation   0.186  ‚ñà‚ñà‚ñà\n",
      "  [9] Commute      0.172  ‚ñà‚ñà‚ñà\n",
      "\n",
      "Actions:\n",
      "  [Enter] Confirm Top Match\n",
      "  [0-9]   Select specific category above\n",
      "  [n]     Create NEW Category\n",
      "‚ùå Invalid selection. Learning skipped.\n",
      "------------------------------------------------------------\n",
      "0.5442309975624084 <class 'float'>\n",
      "\n",
      "üìù Input: 'wash dog'\n",
      "ü§ñ Top Prediction: Errands (0.544)\n",
      "\n",
      "Scores:\n",
      "  [0] Errands      0.544  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [1] Meditation   0.299  ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [2] Break        0.296  ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [3] Sleep        0.296  ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [4] Eat          0.295  ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [5] Leisure      0.275  ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [6] Commute      0.269  ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [7] Fitness      0.261  ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [8] Coding       0.251  ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [9] Study        0.250  ‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Actions:\n",
      "  [Enter] Confirm Top Match\n",
      "  [0-9]   Select specific category above\n",
      "  [n]     Create NEW Category\n",
      "‚ùå Invalid selection. Learning skipped.\n",
      "------------------------------------------------------------\n",
      "0.49059733748435974 <class 'float'>\n",
      "\n",
      "üìù Input: 'walk dog'\n",
      "ü§ñ Top Prediction: Commute (0.491)\n",
      "\n",
      "Scores:\n",
      "  [0] Commute      0.491  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [1] Fitness      0.489  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [2] Errands      0.418  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [3] Meditation   0.408  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [4] Eat          0.408  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [5] Break        0.404  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [6] Leisure      0.396  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [7] Study        0.383  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [8] Sleep        0.380  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [9] Coding       0.374  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Actions:\n",
      "  [Enter] Confirm Top Match\n",
      "  [0-9]   Select specific category above\n",
      "  [n]     Create NEW Category\n",
      "‚ùå Invalid selection. Learning skipped.\n",
      "------------------------------------------------------------\n",
      "0.5068034529685974 <class 'float'>\n",
      "\n",
      "üìù Input: 'dog eating cookie'\n",
      "ü§ñ Top Prediction: Eat (0.507)\n",
      "\n",
      "Scores:\n",
      "  [0] Eat          0.507  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [1] Leisure      0.322  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [2] Sleep        0.322  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [3] Break        0.320  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [4] Commute      0.289  ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [5] Study        0.284  ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [6] Coding       0.272  ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [7] Fitness      0.269  ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [8] Work         0.259  ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [9] Errands      0.255  ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Actions:\n",
      "  [Enter] Confirm Top Match\n",
      "  [0-9]   Select specific category above\n",
      "  [n]     Create NEW Category\n",
      "‚ùå Invalid selection. Learning skipped.\n",
      "------------------------------------------------------------\n",
      "0.4364964962005615 <class 'float'>\n",
      "\n",
      "üìù Input: 'water plants'\n",
      "ü§ñ Top Prediction: Eat (0.436)\n",
      "\n",
      "Scores:\n",
      "  [0] Eat          0.436  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [1] Meditation   0.429  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [2] Study        0.378  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [3] Leisure      0.374  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [4] Fitness      0.367  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [5] Errands      0.360  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [6] Break        0.356  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [7] Commute      0.335  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [8] Coding       0.320  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [9] Sleep        0.296  ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Actions:\n",
      "  [Enter] Confirm Top Match\n",
      "  [0-9]   Select specific category above\n",
      "  [n]     Create NEW Category\n",
      "------------------------------------------------------------\n",
      "0.5234286189079285 <class 'float'>\n",
      "\n",
      "üìù Input: 'water plants'\n",
      "ü§ñ Top Prediction: Errands (0.523)\n",
      "\n",
      "Scores:\n",
      "  [0] Errands      0.523  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [1] Eat          0.436  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [2] Meditation   0.429  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [3] Study        0.378  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [4] Leisure      0.374  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [5] Fitness      0.367  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [6] Break        0.356  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [7] Commute      0.335  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [8] Coding       0.320  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "  [9] Sleep        0.296  ‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Actions:\n",
      "  [Enter] Confirm Top Match\n",
      "  [0-9]   Select specific category above\n",
      "  [n]     Create NEW Category\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  [0-9]   Select specific category above\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  [n]     Create NEW Category\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m choice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSelect correct category: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     41\u001b[0m selected_category \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# CASE A: Confirm Top Match\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/time-tracker-ml/lib/python3.10/site-packages/ipykernel/kernelbase.py:1396\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1394\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1395\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_shell_context_var\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shell_parent_ident\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1399\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1401\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/time-tracker-ml/lib/python3.10/site-packages/ipykernel/kernelbase.py:1441\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1440\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1441\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1443\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "from scorer import Scorer\n",
    "import time\n",
    "\n",
    "model = Scorer(data)\n",
    "model.initialize_vectors()\n",
    "\n",
    "while True:\n",
    "    print(\"-\" * 60)\n",
    "    input_text = input(\"Enter activity (or 'q' to quit): \")\n",
    "    \n",
    "    if input_text.lower() in ['q', 'quit', 'exit']:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "        \n",
    "    if not input_text.strip():\n",
    "        continue\n",
    "    \n",
    "    predictions = model.predict(input_text)\n",
    "    top_category = predictions[0][0]\n",
    "    top_score = predictions[0][1]\n",
    "    \n",
    "    print(top_score, type(top_score))\n",
    "\n",
    "    # 2. Display Dashboard\n",
    "    print(f\"\\nüìù Input: '{input_text}'\")\n",
    "    print(f\"ü§ñ Top Prediction: {top_category} ({top_score:.3f})\\n\")\n",
    "    \n",
    "    print(\"Scores:\")\n",
    "    for i, (cat, score) in enumerate(predictions[:10]): # Show Top 10\n",
    "        bar = \"‚ñà\" * int(score * 20)\n",
    "        print(f\"  [{i}] {cat:<12} {score:.3f}  {bar}\")\n",
    "    \n",
    "    # 3. User Feedback Loop\n",
    "    print(\"\\nActions:\")\n",
    "    print(\"  [Enter] Confirm Top Match\")\n",
    "    print(\"  [0-9]   Select specific category above\")\n",
    "    print(\"  [n]     Create NEW Category\")\n",
    "    \n",
    "    choice = input(\"Select correct category: \").strip().lower()\n",
    "    \n",
    "    selected_category = None\n",
    "    \n",
    "    # CASE A: Confirm Top Match\n",
    "    if choice == \"\":\n",
    "        selected_category = top_category\n",
    "        # Only learn if confidence was low, otherwise skip to save space (Optional rule)\n",
    "        if top_score < 0.8: \n",
    "            model.update_descriptions(selected_category, input_text)\n",
    "        else:\n",
    "            print(\"‚úÖ High confidence match. No update needed.\")\n",
    "\n",
    "    # CASE B: Select from List\n",
    "    elif choice.isdigit() and 0 <= int(choice) < 10:\n",
    "        idx = int(choice)\n",
    "        selected_category = predictions[idx][0]\n",
    "        # This is a correction, so we ALWAYS update\n",
    "        model.update_descriptions(selected_category, input_text)\n",
    "\n",
    "    # CASE C: Create New Category\n",
    "    elif choice == 'n':\n",
    "        new_cat_name = input(\"Enter name for NEW category: \").strip().title()\n",
    "        if new_cat_name:\n",
    "            selected_category = new_cat_name\n",
    "            # Initialize with user input\n",
    "            model.update_descriptions(selected_category, input_text)\n",
    "\n",
    "    # CASE D: Invalid\n",
    "    else:\n",
    "        print(\"‚ùå Invalid selection. Learning skipped.\")\n",
    "\n",
    "    # Pause for effect so user can read result\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38e6733f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac-aroni/miniforge3/envs/time-tracker-ml/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL                                         | K   | ACCURACY | SCORE    | AVG CONF\n",
      "------------------------------------------------------------------------------------------\n",
      "BAAI/bge-base-en-v1.5                         | 1   | 90.0%   |   42.17  | 0.870\n",
      "BAAI/bge-base-en-v1.5                         | 3   | 88.3%   |   38.24  | 0.796\n",
      "BAAI/bge-base-en-v1.5                         | 5   | 90.0%   |   37.50  | 0.757\n",
      "BAAI/bge-base-en-v1.5                         | 7   | 91.7%   |   37.41  | 0.732\n",
      "BAAI/bge-base-en-v1.5                         | 9   | 90.0%   |   35.10  | 0.711\n",
      "BAAI/bge-small-en-v1.5                        | 1   | 83.3%   |   32.12  | 0.888\n",
      "BAAI/bge-small-en-v1.5                        | 3   | 86.7%   |   36.89  | 0.820\n",
      "BAAI/bge-small-en-v1.5                        | 5   | 86.7%   |   35.26  | 0.786\n",
      "BAAI/bge-small-en-v1.5                        | 7   | 86.7%   |   33.60  | 0.764\n",
      "BAAI/bge-small-en-v1.5                        | 9   | 91.7%   |   36.52  | 0.744\n",
      "TaylorAI/gte-tiny                             | 1   | 85.0%   |   30.31  | 0.945\n",
      "TaylorAI/gte-tiny                             | 3   | 86.7%   |   40.10  | 0.912\n",
      "TaylorAI/gte-tiny                             | 5   | 85.0%   |   37.40  | 0.895\n",
      "TaylorAI/gte-tiny                             | 7   | 85.0%   |   37.66  | 0.883\n",
      "TaylorAI/gte-tiny                             | 9   | 85.0%   |   37.20  | 0.873\n",
      "sentence-transformers/all-MiniLM-L6-v2        | 1   | 86.7%   |   35.90  | 0.782\n",
      "sentence-transformers/all-MiniLM-L6-v2        | 3   | 88.3%   |   30.12  | 0.647\n",
      "sentence-transformers/all-MiniLM-L6-v2        | 5   | 88.3%   |   27.72  | 0.577\n",
      "sentence-transformers/all-MiniLM-L6-v2        | 7   | 88.3%   |   25.85  | 0.532\n",
      "sentence-transformers/all-MiniLM-L6-v2        | 9   | 88.3%   |   23.63  | 0.495\n",
      "sentence-transformers/paraphrase-MiniLM-L3-v2 | 1   | 85.0%   |   32.42  | 0.782\n",
      "sentence-transformers/paraphrase-MiniLM-L3-v2 | 3   | 86.7%   |   29.60  | 0.623\n",
      "sentence-transformers/paraphrase-MiniLM-L3-v2 | 5   | 85.0%   |   24.88  | 0.548\n",
      "sentence-transformers/paraphrase-MiniLM-L3-v2 | 7   | 86.7%   |   22.67  | 0.497\n",
      "sentence-transformers/paraphrase-MiniLM-L3-v2 | 9   | 86.7%   |   20.59  | 0.451\n",
      "\n",
      "==========================================================================================\n",
      "‚ùå DETAILED FAILURE LOG (Worst Errors)\n",
      "==========================================================================================\n",
      "\n",
      "üîπ BAAI/bge-base-en-v1.5 (K=1): 6 Errors\n",
      "   ‚Ä¢ 'team meeting' -> Predicted: Social (0.73) | True: Work (Rank #3)\n",
      "   ‚Ä¢ 'watching lecture' -> Predicted: Entertainment (0.76) | True: Study (Rank #3)\n",
      "   ‚Ä¢ 'emails' -> Predicted: Social (0.62) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'client call' -> Predicted: Social (0.77) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'grocery shopping' -> Predicted: Eat (0.73) | True: Chores (Rank #2)\n",
      "   ‚Ä¢ 'photography' -> Predicted: Work (0.68) | True: Hobby (Rank #2)\n",
      "\n",
      "üîπ BAAI/bge-base-en-v1.5 (K=3): 7 Errors\n",
      "   ‚Ä¢ 'team meeting' -> Predicted: Social (0.71) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'emails' -> Predicted: Social (0.59) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'client call' -> Predicted: Social (0.68) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'watching lecture' -> Predicted: Entertainment (0.74) | True: Study (Rank #2)\n",
      "   ‚Ä¢ 'grocery shopping' -> Predicted: Eat (0.69) | True: Chores (Rank #2)\n",
      "   ‚Ä¢ 'taking a bath' -> Predicted: Chores (0.69) | True: Self Care (Rank #2)\n",
      "   ‚Ä¢ 'photography' -> Predicted: Work (0.64) | True: Hobby (Rank #2)\n",
      "\n",
      "üîπ BAAI/bge-base-en-v1.5 (K=5): 6 Errors\n",
      "   ‚Ä¢ 'team meeting' -> Predicted: Social (0.69) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'emails' -> Predicted: Social (0.57) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'client call' -> Predicted: Social (0.64) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'watching lecture' -> Predicted: Entertainment (0.71) | True: Study (Rank #2)\n",
      "   ‚Ä¢ 'grocery shopping' -> Predicted: Eat (0.67) | True: Chores (Rank #2)\n",
      "   ‚Ä¢ 'taking a bath' -> Predicted: Chores (0.68) | True: Self Care (Rank #2)\n",
      "\n",
      "üîπ BAAI/bge-base-en-v1.5 (K=7): 5 Errors\n",
      "   ‚Ä¢ 'team meeting' -> Predicted: Social (0.68) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'emails' -> Predicted: Social (0.55) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'watching lecture' -> Predicted: Entertainment (0.69) | True: Study (Rank #2)\n",
      "   ‚Ä¢ 'grocery shopping' -> Predicted: Eat (0.66) | True: Chores (Rank #2)\n",
      "   ‚Ä¢ 'taking a bath' -> Predicted: Chores (0.67) | True: Self Care (Rank #2)\n",
      "\n",
      "üîπ BAAI/bge-base-en-v1.5 (K=9): 6 Errors\n",
      "   ‚Ä¢ 'team meeting' -> Predicted: Social (0.66) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'emails' -> Predicted: Social (0.54) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'watching lecture' -> Predicted: Entertainment (0.66) | True: Study (Rank #2)\n",
      "   ‚Ä¢ 'grocery shopping' -> Predicted: Eat (0.65) | True: Chores (Rank #2)\n",
      "   ‚Ä¢ 'skincare routine' -> Predicted: Chores (0.60) | True: Self Care (Rank #2)\n",
      "   ‚Ä¢ 'taking a bath' -> Predicted: Chores (0.66) | True: Self Care (Rank #2)\n",
      "\n",
      "üîπ BAAI/bge-small-en-v1.5 (K=1): 10 Errors\n",
      "   ‚Ä¢ 'emails' -> Predicted: Social (0.73) | True: Work (Rank #6)\n",
      "   ‚Ä¢ 'coding' -> Predicted: Study (0.73) | True: Work (Rank #3)\n",
      "   ‚Ä¢ 'team meeting' -> Predicted: Social (0.81) | True: Work (Rank #3)\n",
      "   ‚Ä¢ 'grocery shopping' -> Predicted: Eat (0.78) | True: Chores (Rank #3)\n",
      "   ‚Ä¢ 'taking a bath' -> Predicted: Chores (0.75) | True: Self Care (Rank #3)\n",
      "   ‚Ä¢ 'client call' -> Predicted: Social (0.79) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'watching lecture' -> Predicted: Entertainment (0.76) | True: Study (Rank #2)\n",
      "   ‚Ä¢ 'yoga' -> Predicted: Self Care (0.79) | True: Exercise (Rank #2)\n",
      "   ‚Ä¢ 'party' -> Predicted: Eat (0.72) | True: Social (Rank #2)\n",
      "   ‚Ä¢ 'photography' -> Predicted: Self Care (0.68) | True: Hobby (Rank #2)\n",
      "\n",
      "üîπ BAAI/bge-small-en-v1.5 (K=3): 8 Errors\n",
      "   ‚Ä¢ 'emails' -> Predicted: Social (0.68) | True: Work (Rank #3)\n",
      "   ‚Ä¢ 'coding' -> Predicted: Study (0.69) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'team meeting' -> Predicted: Social (0.74) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'client call' -> Predicted: Social (0.70) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'watching lecture' -> Predicted: Entertainment (0.75) | True: Study (Rank #2)\n",
      "   ‚Ä¢ 'grocery shopping' -> Predicted: Eat (0.75) | True: Chores (Rank #2)\n",
      "   ‚Ä¢ 'yoga' -> Predicted: Self Care (0.76) | True: Exercise (Rank #2)\n",
      "   ‚Ä¢ 'taking a bath' -> Predicted: Chores (0.74) | True: Self Care (Rank #2)\n",
      "\n",
      "üîπ BAAI/bge-small-en-v1.5 (K=5): 8 Errors\n",
      "   ‚Ä¢ 'emails' -> Predicted: Social (0.65) | True: Work (Rank #3)\n",
      "   ‚Ä¢ 'team meeting' -> Predicted: Social (0.72) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'client call' -> Predicted: Social (0.65) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'watching lecture' -> Predicted: Entertainment (0.72) | True: Study (Rank #2)\n",
      "   ‚Ä¢ 'grocery shopping' -> Predicted: Eat (0.73) | True: Chores (Rank #2)\n",
      "   ‚Ä¢ 'yoga' -> Predicted: Self Care (0.74) | True: Exercise (Rank #2)\n",
      "   ‚Ä¢ 'skincare routine' -> Predicted: Chores (0.69) | True: Self Care (Rank #2)\n",
      "   ‚Ä¢ 'taking a bath' -> Predicted: Chores (0.73) | True: Self Care (Rank #2)\n",
      "\n",
      "üîπ BAAI/bge-small-en-v1.5 (K=7): 8 Errors\n",
      "   ‚Ä¢ 'emails' -> Predicted: Social (0.63) | True: Work (Rank #3)\n",
      "   ‚Ä¢ 'taking a bath' -> Predicted: Chores (0.72) | True: Self Care (Rank #3)\n",
      "   ‚Ä¢ 'coding' -> Predicted: Study (0.65) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'team meeting' -> Predicted: Social (0.70) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'client call' -> Predicted: Social (0.63) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'watching lecture' -> Predicted: Entertainment (0.69) | True: Study (Rank #2)\n",
      "   ‚Ä¢ 'grocery shopping' -> Predicted: Eat (0.72) | True: Chores (Rank #2)\n",
      "   ‚Ä¢ 'skincare routine' -> Predicted: Chores (0.68) | True: Self Care (Rank #2)\n",
      "\n",
      "üîπ BAAI/bge-small-en-v1.5 (K=9): 5 Errors\n",
      "   ‚Ä¢ 'emails' -> Predicted: Social (0.62) | True: Work (Rank #3)\n",
      "   ‚Ä¢ 'taking a bath' -> Predicted: Chores (0.71) | True: Self Care (Rank #3)\n",
      "   ‚Ä¢ 'team meeting' -> Predicted: Social (0.69) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'grocery shopping' -> Predicted: Eat (0.72) | True: Chores (Rank #2)\n",
      "   ‚Ä¢ 'skincare routine' -> Predicted: Chores (0.67) | True: Self Care (Rank #2)\n",
      "\n",
      "üîπ TaylorAI/gte-tiny (K=1): 9 Errors\n",
      "   ‚Ä¢ 'team meeting' -> Predicted: Social (0.91) | True: Work (Rank #5)\n",
      "   ‚Ä¢ 'emails' -> Predicted: Social (0.84) | True: Work (Rank #4)\n",
      "   ‚Ä¢ 'client call' -> Predicted: Social (0.91) | True: Work (Rank #4)\n",
      "   ‚Ä¢ 'grocery shopping' -> Predicted: Eat (0.87) | True: Chores (Rank #4)\n",
      "   ‚Ä¢ 'taking a bath' -> Predicted: Commute (0.88) | True: Self Care (Rank #4)\n",
      "   ‚Ä¢ 'party' -> Predicted: Entertainment (0.85) | True: Social (Rank #3)\n",
      "   ‚Ä¢ 'coding' -> Predicted: Social (0.87) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'watching lecture' -> Predicted: Entertainment (0.91) | True: Study (Rank #2)\n",
      "   ‚Ä¢ 'yoga' -> Predicted: Self Care (0.88) | True: Exercise (Rank #2)\n",
      "\n",
      "üîπ TaylorAI/gte-tiny (K=3): 8 Errors\n",
      "   ‚Ä¢ 'emails' -> Predicted: Social (0.83) | True: Work (Rank #3)\n",
      "   ‚Ä¢ 'team meeting' -> Predicted: Social (0.87) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'client call' -> Predicted: Social (0.87) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'watching lecture' -> Predicted: Entertainment (0.90) | True: Study (Rank #2)\n",
      "   ‚Ä¢ 'grocery shopping' -> Predicted: Eat (0.87) | True: Chores (Rank #2)\n",
      "   ‚Ä¢ 'yoga' -> Predicted: Self Care (0.87) | True: Exercise (Rank #2)\n",
      "   ‚Ä¢ 'skincare routine' -> Predicted: Chores (0.84) | True: Self Care (Rank #2)\n",
      "   ‚Ä¢ 'taking a bath' -> Predicted: Chores (0.86) | True: Self Care (Rank #2)\n",
      "\n",
      "üîπ TaylorAI/gte-tiny (K=5): 9 Errors\n",
      "   ‚Ä¢ 'emails' -> Predicted: Break (0.82) | True: Work (Rank #3)\n",
      "   ‚Ä¢ 'team meeting' -> Predicted: Social (0.86) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'client call' -> Predicted: Social (0.86) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'watching lecture' -> Predicted: Entertainment (0.88) | True: Study (Rank #2)\n",
      "   ‚Ä¢ 'grocery shopping' -> Predicted: Eat (0.86) | True: Chores (Rank #2)\n",
      "   ‚Ä¢ 'working out' -> Predicted: Work (0.92) | True: Exercise (Rank #2)\n",
      "   ‚Ä¢ 'yoga' -> Predicted: Self Care (0.86) | True: Exercise (Rank #2)\n",
      "   ‚Ä¢ 'skincare routine' -> Predicted: Chores (0.84) | True: Self Care (Rank #2)\n",
      "   ‚Ä¢ 'taking a bath' -> Predicted: Chores (0.86) | True: Self Care (Rank #2)\n",
      "\n",
      "üîπ TaylorAI/gte-tiny (K=7): 9 Errors\n",
      "   ‚Ä¢ 'team meeting' -> Predicted: Social (0.85) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'emails' -> Predicted: Break (0.82) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'client call' -> Predicted: Social (0.84) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'watching lecture' -> Predicted: Entertainment (0.86) | True: Study (Rank #2)\n",
      "   ‚Ä¢ 'grocery shopping' -> Predicted: Eat (0.85) | True: Chores (Rank #2)\n",
      "   ‚Ä¢ 'working out' -> Predicted: Work (0.91) | True: Exercise (Rank #2)\n",
      "   ‚Ä¢ 'yoga' -> Predicted: Self Care (0.85) | True: Exercise (Rank #2)\n",
      "   ‚Ä¢ 'skincare routine' -> Predicted: Chores (0.83) | True: Self Care (Rank #2)\n",
      "   ‚Ä¢ 'taking a bath' -> Predicted: Chores (0.85) | True: Self Care (Rank #2)\n",
      "\n",
      "üîπ TaylorAI/gte-tiny (K=9): 9 Errors\n",
      "   ‚Ä¢ 'team meeting' -> Predicted: Social (0.84) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'emails' -> Predicted: Break (0.81) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'client call' -> Predicted: Social (0.83) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'watching lecture' -> Predicted: Entertainment (0.85) | True: Study (Rank #2)\n",
      "   ‚Ä¢ 'grocery shopping' -> Predicted: Eat (0.85) | True: Chores (Rank #2)\n",
      "   ‚Ä¢ 'working out' -> Predicted: Work (0.90) | True: Exercise (Rank #2)\n",
      "   ‚Ä¢ 'yoga' -> Predicted: Self Care (0.84) | True: Exercise (Rank #2)\n",
      "   ‚Ä¢ 'skincare routine' -> Predicted: Chores (0.82) | True: Self Care (Rank #2)\n",
      "   ‚Ä¢ 'taking a bath' -> Predicted: Chores (0.84) | True: Self Care (Rank #2)\n",
      "\n",
      "üîπ sentence-transformers/all-MiniLM-L6-v2 (K=1): 8 Errors\n",
      "   ‚Ä¢ 'coding' -> Predicted: Hobby (0.47) | True: Work (Rank #5)\n",
      "   ‚Ä¢ 'team meeting' -> Predicted: Social (0.68) | True: Work (Rank #4)\n",
      "   ‚Ä¢ 'emails' -> Predicted: Social (0.36) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'client call' -> Predicted: Social (0.52) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'watching lecture' -> Predicted: Entertainment (0.62) | True: Study (Rank #2)\n",
      "   ‚Ä¢ 'grocery shopping' -> Predicted: Eat (0.46) | True: Chores (Rank #2)\n",
      "   ‚Ä¢ 'party' -> Predicted: Eat (0.49) | True: Social (Rank #2)\n",
      "   ‚Ä¢ 'taking a bath' -> Predicted: Eat (0.53) | True: Self Care (Rank #2)\n",
      "\n",
      "üîπ sentence-transformers/all-MiniLM-L6-v2 (K=3): 7 Errors\n",
      "   ‚Ä¢ 'taking a bath' -> Predicted: Chores (0.48) | True: Self Care (Rank #5)\n",
      "   ‚Ä¢ 'coding' -> Predicted: Hobby (0.47) | True: Work (Rank #3)\n",
      "   ‚Ä¢ 'team meeting' -> Predicted: Social (0.51) | True: Work (Rank #3)\n",
      "   ‚Ä¢ 'emails' -> Predicted: Social (0.31) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'client call' -> Predicted: Social (0.37) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'watching lecture' -> Predicted: Entertainment (0.57) | True: Study (Rank #2)\n",
      "   ‚Ä¢ 'grocery shopping' -> Predicted: Eat (0.43) | True: Chores (Rank #2)\n",
      "\n",
      "üîπ sentence-transformers/all-MiniLM-L6-v2 (K=5): 7 Errors\n",
      "   ‚Ä¢ 'taking a bath' -> Predicted: Chores (0.46) | True: Self Care (Rank #5)\n",
      "   ‚Ä¢ 'coding' -> Predicted: Hobby (0.43) | True: Work (Rank #3)\n",
      "   ‚Ä¢ 'team meeting' -> Predicted: Social (0.46) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'emails' -> Predicted: Social (0.28) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'client call' -> Predicted: Social (0.29) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'grocery shopping' -> Predicted: Eat (0.41) | True: Chores (Rank #2)\n",
      "   ‚Ä¢ 'skincare routine' -> Predicted: Exercise (0.23) | True: Self Care (Rank #2)\n",
      "\n",
      "üîπ sentence-transformers/all-MiniLM-L6-v2 (K=7): 7 Errors\n",
      "   ‚Ä¢ 'taking a bath' -> Predicted: Chores (0.43) | True: Self Care (Rank #5)\n",
      "   ‚Ä¢ 'coding' -> Predicted: Hobby (0.40) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'team meeting' -> Predicted: Social (0.43) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'emails' -> Predicted: Social (0.27) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'client call' -> Predicted: Social (0.26) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'grocery shopping' -> Predicted: Eat (0.40) | True: Chores (Rank #2)\n",
      "   ‚Ä¢ 'skincare routine' -> Predicted: Exercise (0.21) | True: Self Care (Rank #2)\n",
      "\n",
      "üîπ sentence-transformers/all-MiniLM-L6-v2 (K=9): 7 Errors\n",
      "   ‚Ä¢ 'taking a bath' -> Predicted: Chores (0.40) | True: Self Care (Rank #5)\n",
      "   ‚Ä¢ 'skincare routine' -> Predicted: Exercise (0.19) | True: Self Care (Rank #3)\n",
      "   ‚Ä¢ 'coding' -> Predicted: Hobby (0.38) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'team meeting' -> Predicted: Social (0.40) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'client call' -> Predicted: Social (0.24) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'grocery shopping' -> Predicted: Eat (0.40) | True: Chores (Rank #2)\n",
      "   ‚Ä¢ 'journaling' -> Predicted: Study (0.33) | True: Self Care (Rank #2)\n",
      "\n",
      "üîπ sentence-transformers/paraphrase-MiniLM-L3-v2 (K=1): 9 Errors\n",
      "   ‚Ä¢ 'team meeting' -> Predicted: Social (0.73) | True: Work (Rank #5)\n",
      "   ‚Ä¢ 'taking a bath' -> Predicted: Eat (0.42) | True: Self Care (Rank #5)\n",
      "   ‚Ä¢ 'coding' -> Predicted: Social (0.39) | True: Work (Rank #4)\n",
      "   ‚Ä¢ 'emails' -> Predicted: Social (0.34) | True: Work (Rank #3)\n",
      "   ‚Ä¢ 'coding for fun' -> Predicted: Social (0.41) | True: Hobby (Rank #3)\n",
      "   ‚Ä¢ 'client call' -> Predicted: Social (0.68) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'watching lecture' -> Predicted: Entertainment (0.61) | True: Study (Rank #2)\n",
      "   ‚Ä¢ 'grocery shopping' -> Predicted: Eat (0.39) | True: Chores (Rank #2)\n",
      "   ‚Ä¢ 'mental break' -> Predicted: Self Care (0.77) | True: Break (Rank #2)\n",
      "\n",
      "üîπ sentence-transformers/paraphrase-MiniLM-L3-v2 (K=3): 8 Errors\n",
      "   ‚Ä¢ 'coding' -> Predicted: Social (0.31) | True: Work (Rank #4)\n",
      "   ‚Ä¢ 'team meeting' -> Predicted: Social (0.50) | True: Work (Rank #3)\n",
      "   ‚Ä¢ 'emails' -> Predicted: Social (0.33) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'client call' -> Predicted: Social (0.43) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'grocery shopping' -> Predicted: Eat (0.35) | True: Chores (Rank #2)\n",
      "   ‚Ä¢ 'working out' -> Predicted: Work (0.69) | True: Exercise (Rank #2)\n",
      "   ‚Ä¢ 'taking a bath' -> Predicted: Chores (0.39) | True: Self Care (Rank #2)\n",
      "   ‚Ä¢ 'coding for fun' -> Predicted: Social (0.35) | True: Hobby (Rank #2)\n",
      "\n",
      "üîπ sentence-transformers/paraphrase-MiniLM-L3-v2 (K=5): 9 Errors\n",
      "   ‚Ä¢ 'coding' -> Predicted: Study (0.24) | True: Work (Rank #4)\n",
      "   ‚Ä¢ 'team meeting' -> Predicted: Social (0.40) | True: Work (Rank #3)\n",
      "   ‚Ä¢ 'taking a bath' -> Predicted: Chores (0.37) | True: Self Care (Rank #3)\n",
      "   ‚Ä¢ 'emails' -> Predicted: Social (0.26) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'client call' -> Predicted: Social (0.34) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'grocery shopping' -> Predicted: Eat (0.33) | True: Chores (Rank #2)\n",
      "   ‚Ä¢ 'working out' -> Predicted: Work (0.65) | True: Exercise (Rank #2)\n",
      "   ‚Ä¢ 'journaling' -> Predicted: Study (0.45) | True: Self Care (Rank #2)\n",
      "   ‚Ä¢ 'coding for fun' -> Predicted: Social (0.31) | True: Hobby (Rank #2)\n",
      "\n",
      "üîπ sentence-transformers/paraphrase-MiniLM-L3-v2 (K=7): 8 Errors\n",
      "   ‚Ä¢ 'coding' -> Predicted: Study (0.21) | True: Work (Rank #4)\n",
      "   ‚Ä¢ 'team meeting' -> Predicted: Social (0.35) | True: Work (Rank #3)\n",
      "   ‚Ä¢ 'journaling' -> Predicted: Study (0.41) | True: Self Care (Rank #3)\n",
      "   ‚Ä¢ 'taking a bath' -> Predicted: Chores (0.35) | True: Self Care (Rank #3)\n",
      "   ‚Ä¢ 'emails' -> Predicted: Social (0.23) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'client call' -> Predicted: Social (0.29) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'grocery shopping' -> Predicted: Eat (0.31) | True: Chores (Rank #2)\n",
      "   ‚Ä¢ 'working out' -> Predicted: Work (0.62) | True: Exercise (Rank #2)\n",
      "\n",
      "üîπ sentence-transformers/paraphrase-MiniLM-L3-v2 (K=9): 8 Errors\n",
      "   ‚Ä¢ 'coding' -> Predicted: Study (0.19) | True: Work (Rank #4)\n",
      "   ‚Ä¢ 'team meeting' -> Predicted: Social (0.31) | True: Work (Rank #3)\n",
      "   ‚Ä¢ 'journaling' -> Predicted: Study (0.38) | True: Self Care (Rank #3)\n",
      "   ‚Ä¢ 'taking a bath' -> Predicted: Chores (0.32) | True: Self Care (Rank #3)\n",
      "   ‚Ä¢ 'emails' -> Predicted: Social (0.20) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'client call' -> Predicted: Social (0.25) | True: Work (Rank #2)\n",
      "   ‚Ä¢ 'grocery shopping' -> Predicted: Eat (0.28) | True: Chores (Rank #2)\n",
      "   ‚Ä¢ 'working out' -> Predicted: Work (0.58) | True: Exercise (Rank #2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scorer import Scorer\n",
    "\n",
    "data = {\n",
    "    \"Sleep\": [\n",
    "        \"sleeping\",\n",
    "        \"going to sleep\",\n",
    "        \"taking a nap\",\n",
    "        \"napping\",\n",
    "        \"heading to bed\",\n",
    "        \"lying in bed\",\n",
    "        \"trying to sleep\",\n",
    "        \"resting\",\n",
    "        \"fell asleep\",\n",
    "        \"waking up\"\n",
    "    ],\n",
    "\n",
    "    \"Eat\": [\n",
    "        \"eating\",\n",
    "        \"having a meal\",\n",
    "        \"eating food\",\n",
    "        \"having breakfast\",\n",
    "        \"having lunch\",\n",
    "        \"having dinner\",\n",
    "        \"grabbing a snack\",\n",
    "        \"snacking\",\n",
    "        \"drinking water\",\n",
    "        \"getting food\"\n",
    "    ],\n",
    "\n",
    "    \"Work\": [\n",
    "        \"working\",\n",
    "        \"doing work\",\n",
    "        \"at work\",\n",
    "        \"working on tasks\",\n",
    "        \"working on my job\",\n",
    "        \"doing my job\",\n",
    "        \"office work\",\n",
    "        \"working on a project\",\n",
    "        \"career work\",\n",
    "        \"business work\"\n",
    "    ],\n",
    "\n",
    "    \"Study\": [\n",
    "        \"studying\",\n",
    "        \"doing homework\",\n",
    "        \"studying for an exam\",\n",
    "        \"learning\",\n",
    "        \"reading notes\",\n",
    "        \"reviewing material\",\n",
    "        \"doing school work\",\n",
    "        \"working on assignments\",\n",
    "        \"exam prep\",\n",
    "        \"studying concepts\"\n",
    "    ],\n",
    "\n",
    "    \"Commute\": [\n",
    "        \"commuting\",\n",
    "        \"driving to work\",\n",
    "        \"traveling\",\n",
    "        \"on the way\",\n",
    "        \"heading somewhere\",\n",
    "        \"walking to class\",\n",
    "        \"taking the bus\",\n",
    "        \"riding the train\",\n",
    "        \"driving\",\n",
    "        \"going somewhere\"\n",
    "    ],\n",
    "\n",
    "    \"Entertainment\": [\n",
    "        \"watching tv\",\n",
    "        \"watching a show\",\n",
    "        \"watching a movie\",\n",
    "        \"playing games\",\n",
    "        \"gaming\",\n",
    "        \"scrolling social media\",\n",
    "        \"watching youtube\",\n",
    "        \"browsing the internet\",\n",
    "        \"entertainment\",\n",
    "        \"relaxing with media\"\n",
    "    ],\n",
    "\n",
    "    \"Chores\": [\n",
    "        \"doing chores\",\n",
    "        \"cleaning\",\n",
    "        \"doing laundry\",\n",
    "        \"washing dishes\",\n",
    "        \"tidying up\",\n",
    "        \"housework\",\n",
    "        \"organizing\",\n",
    "        \"cleaning the house\",\n",
    "        \"taking care of chores\",\n",
    "        \"running household tasks\"\n",
    "    ],\n",
    "\n",
    "    \"Exercise\": [\n",
    "        \"working out\",\n",
    "        \"exercising\",\n",
    "        \"going to the gym\",\n",
    "        \"lifting weights\",\n",
    "        \"doing cardio\",\n",
    "        \"running\",\n",
    "        \"jogging\",\n",
    "        \"walking\",\n",
    "        \"training\",\n",
    "        \"fitness\"\n",
    "    ],\n",
    "\n",
    "    \"Social\": [\n",
    "        \"hanging out\",\n",
    "        \"spending time with friends\",\n",
    "        \"talking with friends\",\n",
    "        \"socializing\",\n",
    "        \"meeting people\",\n",
    "        \"chatting\",\n",
    "        \"calling someone\",\n",
    "        \"texting\",\n",
    "        \"being social\",\n",
    "        \"spending time together\"\n",
    "    ],\n",
    "\n",
    "    \"Break\": [\n",
    "        \"taking a break\",\n",
    "        \"on a break\",\n",
    "        \"resting\",\n",
    "        \"pausing\",\n",
    "        \"stepping away\",\n",
    "        \"short break\",\n",
    "        \"cooling off\",\n",
    "        \"doing nothing\",\n",
    "        \"waiting\",\n",
    "        \"idle\"\n",
    "    ],\n",
    "\n",
    "    \"Self Care\": [\n",
    "        \"self care\",\n",
    "        \"taking care of myself\",\n",
    "        \"relaxing\",\n",
    "        \"meditating\",\n",
    "        \"mindfulness\",\n",
    "        \"journaling\",\n",
    "        \"breathing exercises\",\n",
    "        \"therapy\",\n",
    "        \"mental health\",\n",
    "        \"winding down\"\n",
    "    ],\n",
    "\n",
    "    \"Hobby\": [\n",
    "        \"working on a hobby\",\n",
    "        \"doing a hobby\",\n",
    "        \"creative work\",\n",
    "        \"drawing\",\n",
    "        \"writing\",\n",
    "        \"playing music\",\n",
    "        \"practicing an instrument\",\n",
    "        \"building something\",\n",
    "        \"personal project\",\n",
    "        \"doing something I enjoy\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# --- 1. SETUP DATA ---\n",
    "# (Assuming 'data' is defined in your environment or imported)\n",
    "# If not, paste the 'category_data' dictionary here from our previous conversation.\n",
    "\n",
    "labeled_tests = [\n",
    "    (\"went to bed\", \"Sleep\"),\n",
    "    (\"sleeping\", \"Sleep\"),\n",
    "    (\"took a nap\", \"Sleep\"),\n",
    "    (\"power nap\", \"Sleep\"),\n",
    "    (\"resting in bed\", \"Sleep\"),\n",
    "\n",
    "    (\"had breakfast\", \"Eat\"),\n",
    "    (\"ate lunch\", \"Eat\"),\n",
    "    (\"grabbing food\", \"Eat\"),\n",
    "    (\"cooking dinner\", \"Eat\"),\n",
    "    (\"late night snack\", \"Eat\"),\n",
    "\n",
    "    (\"working\", \"Work\"),\n",
    "    (\"coding\", \"Work\"),\n",
    "    (\"team meeting\", \"Work\"),\n",
    "    (\"emails\", \"Work\"),\n",
    "    (\"client call\", \"Work\"),\n",
    "\n",
    "    (\"studying\", \"Study\"),\n",
    "    (\"homework\", \"Study\"),\n",
    "    (\"reviewing notes\", \"Study\"),\n",
    "    (\"exam prep\", \"Study\"),\n",
    "    (\"watching lecture\", \"Study\"),\n",
    "\n",
    "    (\"commuting\", \"Commute\"),\n",
    "    (\"driving to work\", \"Commute\"),\n",
    "    (\"bus ride\", \"Commute\"),\n",
    "    (\"walking to campus\", \"Commute\"),\n",
    "    (\"train ride home\", \"Commute\"),\n",
    "\n",
    "    (\"watching TV\", \"Entertainment\"),\n",
    "    (\"Netflix\", \"Entertainment\"),\n",
    "    (\"playing video games\", \"Entertainment\"),\n",
    "    (\"scrolling TikTok\", \"Entertainment\"),\n",
    "    (\"watching YouTube\", \"Entertainment\"),\n",
    "\n",
    "    (\"cleaning room\", \"Chores\"),\n",
    "    (\"doing laundry\", \"Chores\"),\n",
    "    (\"washing dishes\", \"Chores\"),\n",
    "    (\"taking out trash\", \"Chores\"),\n",
    "    (\"grocery shopping\", \"Chores\"),\n",
    "\n",
    "    (\"working out\", \"Exercise\"),\n",
    "    (\"gym session\", \"Exercise\"),\n",
    "    (\"running\", \"Exercise\"),\n",
    "    (\"yoga\", \"Exercise\"),\n",
    "    (\"lifting weights\", \"Exercise\"),\n",
    "\n",
    "    (\"hanging out with friends\", \"Social\"),\n",
    "    (\"meeting friends\", \"Social\"),\n",
    "    (\"party\", \"Social\"),\n",
    "    (\"chatting with people\", \"Social\"),\n",
    "    (\"catching up with friends\", \"Social\"),\n",
    "\n",
    "    (\"taking a break\", \"Break\"),\n",
    "    (\"coffee break\", \"Break\"),\n",
    "    (\"short break\", \"Break\"),\n",
    "    (\"stepping away\", \"Break\"),\n",
    "    (\"mental break\", \"Break\"),\n",
    "\n",
    "    (\"self care\", \"Self Care\"),\n",
    "    (\"skincare routine\", \"Self Care\"),\n",
    "    (\"meditating\", \"Self Care\"),\n",
    "    (\"journaling\", \"Self Care\"),\n",
    "    (\"taking a bath\", \"Self Care\"),\n",
    "\n",
    "    (\"drawing\", \"Hobby\"),\n",
    "    (\"playing guitar\", \"Hobby\"),\n",
    "    (\"photography\", \"Hobby\"),\n",
    "    (\"writing stories\", \"Hobby\"),\n",
    "    (\"coding for fun\", \"Hobby\"),\n",
    "]\n",
    "\n",
    "# List of models to compete against MiniLM-L6\n",
    "models_to_test = [\n",
    "    \"BAAI/bge-base-en-v1.5\",                    # Current Champion (Reference)\n",
    "    \"BAAI/bge-small-en-v1.5\",                   # Top Contender (33MB)\n",
    "    \"TaylorAI/gte-tiny\",                        # Distilled Logic (29MB)\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\",   # Baseline (22MB)\n",
    "    \"sentence-transformers/paraphrase-MiniLM-L3-v2\" # Speed Demon (17MB)\n",
    "]\n",
    "\n",
    "# List of K values to test\n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "\n",
    "print(f\"{'MODEL':<45} | {'K':<3} | {'ACCURACY':<8} | {'SCORE':<8} | {'AVG CONF':<8}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "failures_log = {}\n",
    "\n",
    "for model_name in models_to_test:\n",
    "    try:\n",
    "        model = Scorer(data, model_name)\n",
    "        \n",
    "        if \"e5-small\" in model_name:\n",
    "            model.query_prefix = \"query: \"\n",
    "            model.doc_prefix = \"passage: \"\n",
    "        \n",
    "        model.initialize_vectors()\n",
    "        \n",
    "        for k in k_values:\n",
    "            model.k = k\n",
    "            \n",
    "            total_score = 0\n",
    "            correct_count = 0\n",
    "            conf_sum = 0\n",
    "            current_failures = []\n",
    "            \n",
    "            for text, true_label in labeled_tests:\n",
    "                predictions = model.predict(text)\n",
    "                top_label, top_score = predictions[0]\n",
    "                \n",
    "                conf_sum += top_score\n",
    "                \n",
    "                # Find Rank\n",
    "                labels_only = [p[0] for p in predictions]\n",
    "                try:\n",
    "                    rank = labels_only.index(true_label) + 1\n",
    "                except ValueError:\n",
    "                    rank = 100\n",
    "                \n",
    "                # Scoring Logic\n",
    "                if rank == 1:\n",
    "                    total_score += top_score\n",
    "                    correct_count += 1\n",
    "                else:\n",
    "                    penalty = top_score * (rank - 1)\n",
    "                    total_score -= penalty\n",
    "                    \n",
    "                    current_failures.append({\n",
    "                        \"text\": text,\n",
    "                        \"pred\": top_label,\n",
    "                        \"true\": true_label,\n",
    "                        \"rank\": rank,\n",
    "                        \"conf\": top_score\n",
    "                    })\n",
    "            \n",
    "            accuracy = (correct_count / len(labeled_tests)) * 100\n",
    "            avg_conf = conf_sum / len(labeled_tests)\n",
    "            \n",
    "            print(f\"{model_name:<45} | {k:<3} | {accuracy:.1f}%   | {total_score:>7.2f}  | {avg_conf:.3f}\")\n",
    "            \n",
    "            failures_log[f\"{model_name} (K={k})\"] = current_failures\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"{model_name:<45} | FAILED TO LOAD: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"‚ùå DETAILED FAILURE LOG (Worst Errors)\")\n",
    "print(\"=\"*90)\n",
    "\n",
    "for config, errors in failures_log.items():\n",
    "    if not errors:\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\nüîπ {config}: {len(errors)} Errors\")\n",
    "    \n",
    "    # Sort by Rank (worst failures first)\n",
    "    errors.sort(key=lambda x: x['rank'], reverse=True) \n",
    "    \n",
    "    for err in errors[:10]:\n",
    "        print(f\"   ‚Ä¢ '{err['text']}' -> Predicted: {err['pred']} ({err['conf']:.2f}) | True: {err['true']} (Rank #{err['rank']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8c15c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨áÔ∏è Downloading sentence-transformers/all-MiniLM-L6-v2...\n",
      "üïµÔ∏è Tracing model graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model is not in eval mode. Consider calling '.eval()' on your model prior to conversion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üçè Converting to CoreML...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting PyTorch Frontend ==> MIL Ops:   0%|          | 0/273 [00:00<?, ? ops/s]Core ML embedding (gather) layer does not support any inputs besides the weights and indices. Those given will be ignored.\n",
      "Converting PyTorch Frontend ==> MIL Ops: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 272/273 [00:00<00:00, 5186.51 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 215.48 passes/s]\n",
      "Running MIL default pipeline: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:01<00:00, 82.17 passes/s] \n",
      "Running MIL backend_mlprogram pipeline: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:00<00:00, 265.89 passes/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóúÔ∏è Compressing weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running compression pass linear_quantize_weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 101/101 [00:00<00:00, 152.36 ops/s]\n",
      "Running MIL frontend_milinternal pipeline: 0 passes [00:00, ? passes/s]\n",
      "Running MIL default pipeline: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 92/92 [00:00<00:00, 189.03 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:00<00:00, 242.42 passes/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'MiniLM.mlpackage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 94\u001b[0m\n\u001b[1;32m     91\u001b[0m     model \u001b[38;5;241m=\u001b[39m quantization_utils\u001b[38;5;241m.\u001b[39mquantize_weights(model, nbits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# --- STEP 6: SAVE ---\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Saved Model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# --- STEP 7: SAVE VOCAB ---\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/time-tracker-ml/lib/python3.10/site-packages/coremltools/models/model.py:729\u001b[0m, in \u001b[0;36mMLModel.save\u001b[0;34m(self, save_path)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ext \u001b[38;5;241m!=\u001b[39m _MLPACKAGE_EXTENSION:\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m    725\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor an ML Program, extension must be \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m (not \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m). Please see https://coremltools.readme.io/docs/unified-conversion-api#target-conversion-formats to see the difference between neuralnetwork and mlprogram model types.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    726\u001b[0m             _MLPACKAGE_EXTENSION, ext\n\u001b[1;32m    727\u001b[0m         )\n\u001b[1;32m    728\u001b[0m     )\n\u001b[0;32m--> 729\u001b[0m \u001b[43m_shutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopytree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpackage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mil_program \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    732\u001b[0m     [\n\u001b[1;32m    733\u001b[0m         _ScopeSource\u001b[38;5;241m.\u001b[39mEXIR_DEBUG_HANDLE \u001b[38;5;129;01min\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_essential_scope_sources \u001b[38;5;28;01mfor\u001b[39;00m function \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mil_program\u001b[38;5;241m.\u001b[39mfunctions\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    734\u001b[0m     ]\n\u001b[1;32m    735\u001b[0m ):\n\u001b[1;32m    736\u001b[0m     debug_handle_to_ops_mapping \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    737\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mil_program\u001b[38;5;241m.\u001b[39mconstruct_debug_handle_to_ops_mapping()\n\u001b[1;32m    738\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/time-tracker-ml/lib/python3.10/shutil.py:559\u001b[0m, in \u001b[0;36mcopytree\u001b[0;34m(src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m os\u001b[38;5;241m.\u001b[39mscandir(src) \u001b[38;5;28;01mas\u001b[39;00m itr:\n\u001b[1;32m    558\u001b[0m     entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itr)\n\u001b[0;32m--> 559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_copytree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mentries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msymlinks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mignore_dangling_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_dangling_symlinks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mdirs_exist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirs_exist_ok\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/time-tracker-ml/lib/python3.10/shutil.py:457\u001b[0m, in \u001b[0;36m_copytree\u001b[0;34m(entries, src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    455\u001b[0m     ignored_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m--> 457\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirs_exist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m errors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    459\u001b[0m use_srcentry \u001b[38;5;241m=\u001b[39m copy_function \u001b[38;5;129;01mis\u001b[39;00m copy2 \u001b[38;5;129;01mor\u001b[39;00m copy_function \u001b[38;5;129;01mis\u001b[39;00m copy\n",
      "File \u001b[0;32m~/miniforge3/envs/time-tracker-ml/lib/python3.10/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'MiniLM.mlpackage'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import coremltools as ct\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "output_path = \"MiniLM.mlpackage\"\n",
    "vocab_path = \"vocab.txt\"\n",
    "\n",
    "# --- STEP 0: CLEANUP (CRITICAL) ---\n",
    "# Delete old files to prevent the \"FileNotFound\" or \"FileExists\" errors\n",
    "if os.path.exists(output_path):\n",
    "    print(f\"üßπ Deleting corrupted {output_path}...\")\n",
    "    shutil.rmtree(output_path)\n",
    "\n",
    "if os.path.exists(vocab_path):\n",
    "    os.remove(vocab_path)\n",
    "\n",
    "# --- STEP 1: DOWNLOAD & PREPARE ---\n",
    "print(f\"‚¨áÔ∏è Downloading {model_id}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# Force CPU to avoid architecture conflicts during export\n",
    "base_model = AutoModel.from_pretrained(model_id, return_dict=False).cpu()\n",
    "base_model.eval()\n",
    "\n",
    "# --- STEP 2: WRAPPER (MEAN POOLING) ---\n",
    "class WrappedModel(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        token_embeddings = outputs[0]\n",
    "        \n",
    "        # Mean Pooling Math\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return sum_embeddings / sum_mask\n",
    "\n",
    "traced_model = WrappedModel(base_model)\n",
    "\n",
    "# --- STEP 3: TRACE ---\n",
    "print(\"üïµÔ∏è Tracing model graph...\")\n",
    "example_text = \"Hello world\"\n",
    "tokens = tokenizer(example_text, return_tensors=\"pt\", padding=\"max_length\", max_length=128)\n",
    "input_ids = tokens[\"input_ids\"].cpu()\n",
    "attention_mask = tokens[\"attention_mask\"].cpu()\n",
    "\n",
    "traced_graph = torch.jit.trace(traced_model, (input_ids, attention_mask))\n",
    "\n",
    "# --- STEP 4: CONVERT TO COREML ---\n",
    "print(\"üçè Converting to CoreML...\")\n",
    "model = ct.convert(\n",
    "    traced_graph,\n",
    "    inputs=[\n",
    "        ct.TensorType(name=\"input_ids\", shape=(1, 128), dtype=np.int32),\n",
    "        ct.TensorType(name=\"attention_mask\", shape=(1, 128), dtype=np.int32)\n",
    "    ],\n",
    "    outputs=[ct.TensorType(name=\"embeddings\")],\n",
    "    compute_units=ct.ComputeUnit.ALL,\n",
    "    minimum_deployment_target=ct.target.iOS16\n",
    ")\n",
    "\n",
    "# --- STEP 5: COMPRESS TO INT8 ---\n",
    "print(\"üóúÔ∏è Compressing weights...\")\n",
    "try:\n",
    "    from coremltools.optimize.coreml import (\n",
    "        linear_quantize_weights,\n",
    "        OpLinearQuantizerConfig,\n",
    "        OptimizationConfig\n",
    "    )\n",
    "\n",
    "    # Configure quantization\n",
    "    op_config = OpLinearQuantizerConfig(\n",
    "        mode=\"linear_symmetric\",\n",
    "        weight_threshold=512\n",
    "    )\n",
    "    config = OptimizationConfig(global_config=op_config)\n",
    "    \n",
    "    # Apply\n",
    "    model = linear_quantize_weights(model, config=config)\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Modern optimization API missing. Falling back to legacy...\")\n",
    "    from coremltools.models.neural_network import quantization_utils\n",
    "    model = quantization_utils.quantize_weights(model, nbits=8)\n",
    "\n",
    "# --- STEP 6: SAVE ---\n",
    "model.save(output_path)\n",
    "print(f\"‚úÖ Saved Model: {output_path}\")\n",
    "\n",
    "# --- STEP 7: SAVE VOCAB ---\n",
    "print(\"üìñ Generating vocab.txt...\")\n",
    "vocab = tokenizer.get_vocab()\n",
    "with open(vocab_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    sorted_vocab = sorted(vocab.items(), key=lambda item: item[1])\n",
    "    for word, index in sorted_vocab:\n",
    "        f.write(word + \"\\n\")\n",
    "\n",
    "print(f\"‚úÖ Saved Vocab: {vocab_path}\")\n",
    "print(\"\\nüéâ SUCCESS! Drag 'MiniLM.mlpackage' and 'vocab.txt' into Xcode.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee6d40c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time-tracker-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
